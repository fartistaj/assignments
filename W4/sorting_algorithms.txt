1. I will prove that the average-case time complexity of insertion sort is O(N^2), along with a clear visualization showing the operations involved. For insertion sort, we need to analyze the number of compararisons and swaps required on average when sorting a random array of N elements. In insertion sort, we build sorted array one element at a time. For each element, we compare it with the already sorted elements before it and insert it in the proper postion.

For an array of N elements:
	
	A. The first element is already "sorted" by itself.
	B. For the second element, we need at most 1 comparison.
	C. For the third element, we need at most 2 comparison.
	D. For the ith element, we need at most (i - 1) comparioson.

In the average case with random data, we expect to compare each new element with aobut half of the already sorted elements before finding its correce postion.
So the expected of compariosons is:
	
	A. For the second element: 1 / 2 comparisons
	B. For the third element: 2 / 2 = 1 comparisons.
	C. For the ith element: (i - 1) / 2 comparisons.

The total expected number of comparisons is:
	
	0 + (1 / 2) + (3 / 2) + ... + (N - 1) / 2 = N(N - 1) / 4.

For large N, the term (N - 1)N behave like N^2, so the time complexity is O(N^2).

Initial: [5, 2, 4, 6, 1, 3]
	
	1. Compare 2 with 5: [5], [2]
	   After insertion : [2, 5, 4, 6, 1, 3]
	2. Compare 4 with 5: [5], [4]
 	   After insertion : [2, 4, 5, 6, 1, 3]
	3. Compare 6 with 5: [5], [6]
   	   After insertion : [2, 4, 5, 6, 1, 3]
	4. Compare 1 with 6: [6], [5], [4], [2], [1]
           After insertion : [1, 2, 4, 5, 6, 3]
	5. Compare 3 with 6: [6], [5], [4], [3]
           After insertion : [1, 2, 3, 4, 5, 6]

This process results in quadratic time complexity in the average case, confirming that insertion sort runs in O(N^2) time on average.

2. To solve this problem, we are working with Insertion Sort and considering the worst-case scenario. In the worst-case scenario, the array is sorted in reverse order. Let's assume the array is [5,4,3,2,1]

Step 1. Insert 4
	compare 4 with 5
        Since 5 > 4, shift 5 one position to the right
 	Total operations for step 1 = 2(1 comparison + 1 shift)
	[4, 5, 3, 2, 1]
Step 2. Insert 3
	compare 3 with 5
	Since 5 > 3, shift 5 one position to the right
	compare 3 with 4
	Since 4 > 3, shift 4 one position th the right
	Total operations for step 2 = 4(2 comparisons + 2 shifts)
	[3, 4, 5, 2, 1]
Step 3. Insert 3
	Compare 2 with 5
	Since 5 > 2, shift 5 one position to the right
	Compare 2 with 4
	Sicne 4 > 2, shift 4 one position to the right
	Compare 2 with 3 
	Since 3 > 2, shift 3 one position to the right
	Total operation for step 3 = 6(3 comparisons + 3 shifts)
	[2, 3, 4, 5, 1]
Step 4. Insert 1
	Compare 1 with 5
	Since 5 > 1, shift 5 one position to the right
	compare 1 with 4
	Since 4 > 1, shift 4 one position to the right
	Compare 1 with 3
	Since 3 > 1, shift 3 one position to the right
	Compare 1 with 2
	Since 2 > 1, shift 2 one position to the right
	Total operation for step 4 = 8(4 comparisons + 4 shifts)
	[1, 2, 3, 4, 5]

In the worst-case scenario, where the array is initally sorted in reverse order and N = 5, starting with the index of the inspected value at 1, the total number of operations is 20 operations.

3.a

function containsX(string) {
	foundX = false;
	for(let i = 0; i < string.length; i++) { 
	    if (string[i] === "X") {
		foundX = true; 
	    }
	}
	return foundX; 
} 

The overall time complexity of the function is O(N) in the worst case, and O(1) in the best case.

3.   b

function containsX(string) {
	for(let i = 0; i < string.length; i++) {
	    if (string[i] === "X") {
		return true;
            }
 	}
	return false;
}

The function now returns true immediately upon finding an "X", without checking the rest of the string. This avoids checking the remaining characters in the string after the "X" is found.
Removed the unnecessary foundX varialbe entirely.
This modification improves the efficiency for best and average-case scenarios while maintaining the same worst_case comlpexity.

	
 



 

